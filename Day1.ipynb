{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making an HTTP request\n",
    "\n",
    "As discussed in the slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://pokeapi.co/api/v2/pokemon-species/\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if r.ok:\n",
    "    pprint(r.json())\n",
    "else:\n",
    "    print(r.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_json = \"\"\"\n",
    "{\n",
    "    \"a\": true,\n",
    "    \"b\": {\n",
    "        \"c\": 1,\n",
    "        \"d\": [\n",
    "            {\"x\": 1},\n",
    "            {\"y\": 2}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_json = json.loads(raw_json)\n",
    "parsed_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed_json[\"a\"])\n",
    "print(parsed_json[\"b\"][\"d\"][0][\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps({\"a\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://api.coindesk.com/v1/bpi/historical/close.json?start=2012-01-01&end=2019-09-05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "x = list(r.json()['bpi'].keys())\n",
    "y = list(r.json()['bpi'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Token\n",
    "\n",
    "Go get one of your own from https://github.com/settings/tokens! Don't just steal mine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://api.github.com/orgs/rubikloud/repos\")\n",
    "[repo['full_name'] for repo in r.json()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "GITHUB_TOKEN = \"\"\n",
    "r = requests.get(\"https://api.github.com/orgs/rubikloud/repos\", auth=HTTPBasicAuth(GITHUB_TOKEN, \"\"))\n",
    "if r.ok:\n",
    "    print([repo['full_name'] for repo in r.json()])\n",
    "else:\n",
    "    print(r.status_code, r.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagination\n",
    "\n",
    "In the result above, we can see that GitHub returned some private repositories, as we expected (try opening them in your browser to check!), but it still only returned a handful of repositories. Where did the rest go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice those `Link` headers. Those are GitHub's way of telling us about later or earlier pages. What happens if we iterate over them?\n",
    "\n",
    "Well, first we need to parse them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_github_pagination(link_header):\n",
    "    link_header_parts = link_header.split(\", \")\n",
    "    return {\n",
    "        link_header_part.split(\"; \")[1][5:-1]: link_header_part.split(\"; \")[0][1:-1]\n",
    "        for link_header_part in link_header_parts\n",
    "    }\n",
    "\n",
    "parse_github_pagination(r.headers['Link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. So as long as our response _has_ a `rel=\"next\"` in its `Link` header, we can just keep visiting that page, appending our results together as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = [repo[\"full_name\"] for repo in r.json()]\n",
    "links = parse_github_pagination(r.headers[\"Link\"])\n",
    "while \"next\" in links:\n",
    "    r = requests.get(links[\"next\"], auth=HTTPBasicAuth(GITHUB_TOKEN, \"\"))\n",
    "    links = parse_github_pagination(r.headers[\"Link\"])\n",
    "    repos += [repo[\"full_name\"] for repo in r.json()]\n",
    "\n",
    "repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in repos:\n",
    "    potential_pokemon_name = repo.split('/')[1]\n",
    "    r = requests.get(\"https://pokeapi.co/api/v2/pokemon/%s\" % potential_pokemon_name.lower())\n",
    "    is_pokemon = r.ok\n",
    "    print(\"%s: %s\" % (potential_pokemon_name, is_pokemon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using APIs to Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YELP_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://api.yelp.com/v3/businesses/search?location=Toronto&limit=50\", headers={\"Authorization\": \"Bearer %s\" % YELP_TOKEN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.status_code, r.reason, r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_labels = []\n",
    "for business in r.json()['businesses']:\n",
    "    reviews = requests.get(\"https://api.yelp.com/v3/businesses/%s/reviews\" % business['id'], headers={\"Authorization\": \"Bearer %s\" % YELP_TOKEN}).json()\n",
    "    for review in reviews['reviews']:\n",
    "        review_labels.append((review['text'].rstrip('.'), review['rating']))\n",
    "review_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_features = [(x.split(' '), 'positive' if y > 3 else 'negative') for (x, y) in review_labels]\n",
    "review_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentAnalyzer\n",
    "import nltk.sentiment.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "random.shuffle(review_features)\n",
    "training_docs = review_features[:120]\n",
    "test_docs = review_features[120:]\n",
    "\n",
    "print(\"Training: %d, Testing: %d\" % (len(training_docs), len(test_docs)))\n",
    "\n",
    "sentim_analyzer = SentimentAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_neg = sentim_analyzer.all_words([nltk.sentiment.util.mark_negation(doc) for doc in training_docs])\n",
    "all_words_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "sentim_analyzer.add_feat_extractor(nltk.sentiment.util.extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = sentim_analyzer.apply_features(training_docs)\n",
    "test_set = sentim_analyzer.apply_features(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)\n",
    "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
    "     print('{0}: {1}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "c = defaultdict(int)\n",
    "for x in review_labels:\n",
    "    c[x[1]] += 1\n",
    "\n",
    "plt.bar(c.keys(), c.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(\"https://api.github.com/graphql\", auth=HTTPBasicAuth(GITHUB_TOKEN, \"\"), json={\"query\": \"\"\"\n",
    "query {\n",
    "  organization(login: \"rubikloud\") {\n",
    "    name\n",
    "    repositories(privacy: PRIVATE, first: 5) {\n",
    "      edges {\n",
    "        node {\n",
    "          name\n",
    "          pullRequests(last: 5) {\n",
    "            edges {\n",
    "              node {\n",
    "                title\n",
    "                url\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "6d872c0088c8ff920d38c53b3841b655b91fa0bec220337f063351cf8640fc50"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}